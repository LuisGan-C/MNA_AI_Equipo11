{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBbWMn9ebmi8"
      },
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## **Curso: Inteligencia Artificial y Aprendizaje Automático**\n",
        "\n",
        "### Tecnológico de Monterrey\n",
        "\n",
        "### Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## **Actividad de las Semanas 5 y 6**\n",
        "### **Problema de asignación de créditos: South German Dataset.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiwEw8XsZG2W"
      },
      "source": [
        "## **Nombres y matrículas:**\n",
        "\n",
        "\n",
        "\n",
        "*   Luis Sebastián Gan Cadena - A01186635\n",
        "\n",
        "*   Carlos Pano Hernández - A01066264\n",
        "\n",
        "*   Yocoyani Ehecatzin Pérez Ayala - A01796044\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUxxkjE6shkH"
      },
      "source": [
        "# **Parte I: Partición, análisis y pre-procesamiento de los datos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a08Di3GjkL1Y"
      },
      "source": [
        "## **Ejercicio 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VGEpE4SblfD",
        "outputId": "f8081e22-75e9-4b56-e23b-a4e425faf15f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deep-translator in /opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages (1.11.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages (from deep-translator) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages (from deep-translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "# Aquí deberás incluir todas las librerías que requieras durante esta actividad:\n",
        "!pip install deep-translator\n",
        "\n",
        "import pandas as pd\n",
        "from deep_translator import GoogleTranslator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from imblearn.pipeline import Pipeline as imbPipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, PowerTransformer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_validate\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from imblearn.over_sampling import RandomOverSampler, SVMSMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "K3gUzoM3iRkt"
      },
      "outputs": [],
      "source": [
        "# Si se desean comentar algunos de los Warnings.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "ppyf8TTgb9zq",
        "outputId": "c5a29b04-b554-4a26-edb8-36fb162b9c46"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>running account</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>duration</th>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>moral</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>used</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>height</th>\n",
              "      <td>1049</td>\n",
              "      <td>2799</td>\n",
              "      <td>841</td>\n",
              "      <td>2122</td>\n",
              "      <td>2171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>savings account</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rate</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>famges</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>guarantor</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>living time</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>verm</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>21</td>\n",
              "      <td>36</td>\n",
              "      <td>23</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weitkred</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>residential</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bishkred</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>profession</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pers</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>phone</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>guest died</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>credit</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    0     1    2     3     4\n",
              "running account     1     1    2     1     1\n",
              "duration           18     9   12    12    12\n",
              "moral               4     4    2     4     4\n",
              "used                2     0    9     0     0\n",
              "height           1049  2799  841  2122  2171\n",
              "savings account     1     1    2     1     1\n",
              "time                2     3    4     3     3\n",
              "rate                4     2    2     3     4\n",
              "famges              2     3    2     3     3\n",
              "guarantor           1     1    1     1     1\n",
              "living time         4     2    4     2     4\n",
              "verm                2     1    1     1     2\n",
              "age                21    36   23    39    38\n",
              "weitkred            3     3    3     3     1\n",
              "residential         1     1    1     1     2\n",
              "bishkred            1     2    1     2     2\n",
              "profession          3     3    2     2     2\n",
              "pers                2     1    2     1     2\n",
              "phone               1     1    1     1     1\n",
              "guest died          2     2    2     1     1\n",
              "credit              1     1    1     1     1"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Carga y renombra los nombres de las columnas del alemán al inglés y desplegamos\n",
        "# de nuevo el DataFrame para ver el resultado obtenido:\n",
        "\n",
        "# ************* Inlcuye aquí tu código:*****************************\n",
        "# Leyendo la data\n",
        "# df = pd.read_csv('data/south+german+credit/SouthGermanCredit.asc', delim_whitespace=True)\n",
        "df = pd.read_csv('data/south+german+credit/SouthGermanCredit.asc', delim_whitespace=True)\n",
        "\n",
        "# Traduciendo columnas usando google translator y cambiando los nombres\n",
        "translator = GoogleTranslator(source='de', target='en')\n",
        "translated_cols = []\n",
        "for col in df.columns:\n",
        "    translated_cols.append(translator.translate(col))\n",
        "\n",
        "df.columns = translated_cols\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n",
        "df.head(5).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LckYCS8SlnFo"
      },
      "source": [
        "## **Ejercicio 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tlg8jYbnlqNA",
        "outputId": "a1ab2821-98b7-4838-f459-fa0ff0b7ad5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Revision de la data antes:\n",
            "credit\n",
            "1    700\n",
            "0    300\n",
            "Name: count, dtype: int64\n",
            "credit\n",
            "0    700\n",
            "1    300\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Realiza a continuación una transformación para que la clase negativa (buen cliente)\n",
        "# quede con el valor de 0 y la clase positiva (mal cliente) quede con el valor de 1.\n",
        "\n",
        "# ************* Inlcuye aquí tu código:*****************************\n",
        "target_value = 'credit'\n",
        "\n",
        "print(f\"Revision de la data antes:\")\n",
        "print(df[target_value].value_counts())\n",
        "\n",
        "dict_to_map = {0:1,\n",
        "               1:0}\n",
        "\n",
        "df[target_value] = df[target_value].map(dict_to_map)\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n",
        "\n",
        "print(df[target_value].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQx2lbzTkEsQ"
      },
      "source": [
        "## **Ejercicio 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP5-zdWVczhy",
        "outputId": "af37d954-9f25-4b2a-d564-50f277ebedf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones:\n",
            "Entrenamiento: (700, 20) (700, 1)\n",
            "Prueba: (300, 20) (300, 1)\n",
            "\n",
            "Porcentaje clases Positiva: 70.00%, y Negativa: 30.00%\n"
          ]
        }
      ],
      "source": [
        "# Realiza una partición solicitada de entrenamiento y prueba.\n",
        "# Los nombres de los conjuntos deberán ser como se indican en los print de abajo:\n",
        "\n",
        "# ************* Inlcuye aquí tu código:*****************************\n",
        "\n",
        "X = df.iloc[:,:-1]\n",
        "y = df[[target_value]]\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=.3, shuffle=True, random_state=1, stratify=y)\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n",
        "\n",
        "\n",
        "# Mostremos las dimensiones de la partición generada:\n",
        "print(\"Dimensiones:\")\n",
        "print(\"Entrenamiento:\", Xtrain.shape, ytrain.shape)\n",
        "print(\"Prueba:\", Xtest.shape, ytest.shape)\n",
        "\n",
        "# Y el porcentaje de cada clase de la variable de salida:\n",
        "tmp = ytrain.sum()/ytrain.shape[0]\n",
        "print(\"\\nPorcentaje clases Positiva: %.2f%%, y Negativa: %.2f%%\" % (100*(1-tmp),tmp*100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptwAm_mOjVWH"
      },
      "source": [
        "### **Con base al porcentaje de los niveles de la variable de salida ¿podemos decir que tenemos un problema de datos desbalanceado? ¿Por qué?**\n",
        "\n",
        "\n",
        "\n",
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "Sí, podemos afirmar que hay un problema de datos desbalanceados en este contexto de asignación de créditos. La variable de salida presenta un 70% de casos en los que se otorga el crédito (clase positiva) y un 30% donde no se otorga (clase negativa). Esta disparidad es significativa y puede tener varias implicaciones para el modelo de evaluación de riesgos.\n",
        "\n",
        "1. **Impacto en la toma de decisiones**: La mayor representación de la clase positiva puede hacer que el modelo desarrolle una tendencia a predecir que los créditos siempre se otorgan. Esto puede resultar en una alta tasa de aciertos, pero también en una alta tasa de falsos positivos, donde se conceden créditos a personas que podrían no ser confiables.\n",
        "\n",
        "2. **Riesgo financiero**: Si el modelo no identifica adecuadamente a los deudores de alto riesgo (clase negativa), el prestamista podría incurrir en pérdidas significativas debido a impagos. Por otro lado, si se niega el crédito a personas confiables, se pierde la oportunidad de ingresos.\n",
        "\n",
        "3. **Consecuencias sociales**: La negativa a otorgar créditos puede perpetuar desigualdades, afectando desproporcionadamente a ciertos grupos de personas. Esto puede tener un impacto negativo en la reputación del prestamista y en la confianza del consumidor.\n",
        "\n",
        "### **Recomendaciones para abordar el desbalance de clases**:\n",
        "\n",
        "1. **Recolección de datos**: Si es posible, intenta recopilar más datos sobre la clase negativa (no se otorga el crédito) para equilibrar el conjunto de datos.\n",
        "\n",
        "2. **Sobremuestreo**: Utiliza técnicas como SMOTE (Synthetic Minority Over-sampling Technique) para generar ejemplos sintéticos de la clase negativa, lo que puede ayudar a equilibrar el conjunto de datos.\n",
        "\n",
        "3. **Submuestreo**: Considera reducir el número de ejemplos de la clase positiva si no es viable aumentar la clase negativa. Esto debe hacerse con cuidado para no perder información valiosa.\n",
        "\n",
        "4. **Uso de métricas adecuadas**: Evalúa el rendimiento del modelo utilizando métricas como el F1-score, la precisión y el recall, que son más informativas en contextos desbalanceados que la simple precisión.\n",
        "\n",
        "5. **Modelos ajustados**: Implementa algoritmos que manejen bien el desbalance de clases, como árboles de decisión o modelos de ensemble que permiten ajustar la penalización en las clases.\n",
        "\n",
        "6. **Análisis de riesgo**: Realiza un análisis de riesgo más profundo que considere no solo la tasa de aprobación, sino también la tasa de impagos y el impacto financiero de cada decisión de crédito.\n",
        "\n",
        "Implementar estas recomendaciones puede ayudar a mejorar la precisión y la equidad del modelo, minimizando el riesgo tanto de impagos como de rechazos indebidos.\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocmGcSC2j_2x"
      },
      "source": [
        "## **Ejercicio 4**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5J2kIzLYHPZP"
      },
      "outputs": [],
      "source": [
        "# De acuerdo a la información de la Tabla 3 del artículo de la IEEE\n",
        "# define las variables correspondientes que se indican a continuación:\n",
        "\n",
        "# ************* Inlcuye aquí tu código:*****************************\n",
        "\n",
        "# Variables numéricas:\n",
        "lista_paper_num = ['duration', 'height', 'age', 'pers']\n",
        "\n",
        "\n",
        "# Variables ordinales:\n",
        "lista_paper_ord = ['time', 'rate', 'living time', 'verm', 'bishkred', 'profession']\n",
        "\n",
        "\n",
        "# Variables nominales:\n",
        "lista_paper_cat = ['running account', 'moral', 'used', 'savings account', 'famges',\n",
        "                   'guarantor', 'weitkred', 'residential', 'phone', 'guest died']\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb5bE4WJj8Rw"
      },
      "source": [
        "## **Ejercicio 5**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztjTHIZZlG0v"
      },
      "source": [
        "### Análisis Variables Numéricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NvNYiIp9weCm"
      },
      "outputs": [],
      "source": [
        "# Transformaciones que se aplicarán a las variables numéricas usando la clase Pipeline de sklearn:\n",
        "\n",
        "# ************* Incluye aquí tu código:*****************************\n",
        "\n",
        "# Variables numéricas:\n",
        "numericas_pipe = Pipeline(steps=[\n",
        "    ('minmax_scaler', MinMaxScaler())\n",
        "])\n",
        "numericas_pipe_nombres = lista_paper_num\n",
        "\n",
        "# Variables categóricas nominales:\n",
        "nominales_pipe = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))  # Codificación OneHot para variables nominales\n",
        "])\n",
        "nominales_pipe_nombres = lista_paper_cat\n",
        "\n",
        "# Variables categóricas ordinales:\n",
        "ordinales_pipe = Pipeline(steps=[\n",
        "    ('ordinal', OrdinalEncoder())  # Codificación ordinal para mantener el orden jerárquico\n",
        "])\n",
        "ordinales_pipe_nombres = lista_paper_ord\n",
        "\n",
        "# Conjuntas las transformaciones de todo tipo de variable y\n",
        "# deja sin procesar aquellas que hayas decidido no transformar:\n",
        "\n",
        "columnasTransformer = ColumnTransformer(transformers=[\n",
        "    ('numericas', numericas_pipe, numericas_pipe_nombres),\n",
        "    ('nominales', nominales_pipe, nominales_pipe_nombres),\n",
        "    ('ordinales', ordinales_pipe, ordinales_pipe_nombres)],\n",
        "    remainder='passthrough'  # Dejar sin procesar las columnas restantes\n",
        ")\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJokj9Diyeu0"
      },
      "source": [
        "## **Ejercicio 6**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3lqBiH5wd1e",
        "outputId": "5a222b71-3e0c-4ce3-d835-bc6635c2be30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensión de las variables de entrada ANTES de las transformaciones: (1000, 20)\n",
            "Dimensión de las variables de entrada DESPUÉS de las transformaciones: (1000, 41)\n"
          ]
        }
      ],
      "source": [
        "# Como se va a utilizar Validación-Cruzada, concatena los conjuntos de entrenamiento y prueba\n",
        "# en uno nuevo conjunto aumentado que llamaremos trainval para utilizar como entrenamiento:\n",
        "\n",
        "\n",
        "# ************* Inlcuye aquí tu código:**************************\n",
        "\n",
        "Xtraintest = pd.concat([Xtrain, Xtest], axis=0)\n",
        "ytraintest = pd.concat([ytrain, ytest], axis=0)\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n",
        "\n",
        "\n",
        "# Veamos cuántas variables nuevas se introducen con las transformaciones One-Hot-Encoding:\n",
        "Xtmp = Xtraintest.copy()\n",
        "tmp = columnasTransformer.fit_transform(Xtmp)\n",
        "print(\"Dimensión de las variables de entrada ANTES de las transformaciones:\", Xtmp.shape)\n",
        "print(\"Dimensión de las variables de entrada DESPUÉS de las transformaciones:\", tmp.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZxyRbHL0gNF"
      },
      "source": [
        "## **Ejercicio 7**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hdi7AAtwd5G",
        "outputId": "d170d9d6-b158-4ae0-fa27-86a75cfb02ac",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> LR\n",
            "\t test_miaccuracy 0.720 (0.030)\n",
            "\t train_miaccuracy 0.740 (0.011)\n",
            "\t test_miprecision 0.722 (0.036)\n",
            "\t train_miprecision 0.738 (0.012)\n",
            "\t test_mirecall 0.717 (0.042)\n",
            "\t train_mirecall 0.744 (0.013)\n",
            "\t test_mifi 0.719 (0.031)\n",
            "\t train_mifi 0.741 (0.012)\n",
            "\t test_miauc 0.792 (0.028)\n",
            "\t train_miauc 0.823 (0.007)\n",
            "\t test_migmean 0.719 (0.030)\n",
            "\t train_migmean 0.740 (0.011)\n",
            ">> kNN\n",
            "\t test_miaccuracy 0.775 (0.031)\n",
            "\t train_miaccuracy 1.000 (0.000)\n",
            "\t test_miprecision 0.712 (0.030)\n",
            "\t train_miprecision 1.000 (0.000)\n",
            "\t test_mirecall 0.930 (0.021)\n",
            "\t train_mirecall 1.000 (0.000)\n",
            "\t test_mifi 0.806 (0.024)\n",
            "\t train_mifi 1.000 (0.000)\n",
            "\t test_miauc 0.868 (0.024)\n",
            "\t train_miauc 1.000 (0.000)\n",
            "\t test_migmean 0.759 (0.035)\n",
            "\t train_migmean 1.000 (0.000)\n",
            ">> DTree\n",
            "\t test_miaccuracy 0.840 (0.023)\n",
            "\t train_miaccuracy 1.000 (0.001)\n",
            "\t test_miprecision 0.791 (0.025)\n",
            "\t train_miprecision 1.000 (0.001)\n",
            "\t test_mirecall 0.927 (0.024)\n",
            "\t train_mirecall 1.000 (0.001)\n",
            "\t test_mifi 0.853 (0.020)\n",
            "\t train_mifi 1.000 (0.001)\n",
            "\t test_miauc 0.841 (0.023)\n",
            "\t train_miauc 1.000 (0.000)\n",
            "\t test_migmean 0.836 (0.024)\n",
            "\t train_migmean 1.000 (0.001)\n",
            ">> RF\n",
            "\t test_miaccuracy 0.855 (0.025)\n",
            "\t train_miaccuracy 0.978 (0.003)\n",
            "\t test_miprecision 0.811 (0.031)\n",
            "\t train_miprecision 0.963 (0.005)\n",
            "\t test_mirecall 0.927 (0.024)\n",
            "\t train_mirecall 0.993 (0.002)\n",
            "\t test_mifi 0.865 (0.022)\n",
            "\t train_mifi 0.978 (0.003)\n",
            "\t test_miauc 0.943 (0.016)\n",
            "\t train_miauc 0.999 (0.000)\n",
            "\t test_migmean 0.851 (0.027)\n",
            "\t train_migmean 0.977 (0.003)\n",
            ">> XGBoost\n",
            "\t test_miaccuracy 0.878 (0.027)\n",
            "\t train_miaccuracy 1.000 (0.000)\n",
            "\t test_miprecision 0.843 (0.031)\n",
            "\t train_miprecision 1.000 (0.000)\n",
            "\t test_mirecall 0.930 (0.024)\n",
            "\t train_mirecall 1.000 (0.000)\n",
            "\t test_mifi 0.884 (0.024)\n",
            "\t train_mifi 1.000 (0.000)\n",
            "\t test_miauc 0.954 (0.016)\n",
            "\t train_miauc 1.000 (0.000)\n",
            "\t test_migmean 0.876 (0.027)\n",
            "\t train_migmean 1.000 (0.000)\n",
            ">> MLP\n",
            "\t test_miaccuracy 0.858 (0.020)\n",
            "\t train_miaccuracy 1.000 (0.000)\n",
            "\t test_miprecision 0.818 (0.022)\n",
            "\t train_miprecision 0.999 (0.001)\n",
            "\t test_mirecall 0.921 (0.025)\n",
            "\t train_mirecall 1.000 (0.000)\n",
            "\t test_mifi 0.867 (0.019)\n",
            "\t train_mifi 1.000 (0.000)\n",
            "\t test_miauc 0.907 (0.017)\n",
            "\t train_miauc 1.000 (0.000)\n",
            "\t test_migmean 0.856 (0.021)\n",
            "\t train_migmean 1.000 (0.000)\n",
            ">> SVM\n",
            "\t test_miaccuracy 0.909 (0.019)\n",
            "\t train_miaccuracy 1.000 (0.000)\n",
            "\t test_miprecision 0.990 (0.006)\n",
            "\t train_miprecision 1.000 (0.000)\n",
            "\t test_mirecall 0.826 (0.037)\n",
            "\t train_mirecall 1.000 (0.000)\n",
            "\t test_mifi 0.900 (0.022)\n",
            "\t train_mifi 1.000 (0.000)\n",
            "\t test_miauc 0.946 (0.015)\n",
            "\t train_miauc 1.000 (0.000)\n",
            "\t test_migmean 0.905 (0.020)\n",
            "\t train_migmean 1.000 (0.000)\n"
          ]
        }
      ],
      "source": [
        "# Definimos a continuación la función que llamamos \"mis_modelos\" que incluye\n",
        "# todos los modelos que deseamos comparar en el ejercicio.\n",
        "\n",
        "\n",
        "def mis_modelos():\n",
        "\n",
        "  modelos, nombres = list(), list()\n",
        "\n",
        "\n",
        "  # ************* Inlcuye aquí tu código:**************************\n",
        "  #\n",
        "  # Deberás incluir en cada modelo los argumentos que consideres\n",
        "  # adecuados para que cada uno converja y no esté sobreentrenado\n",
        "  # con respecto a la métrica de la exatitud (accuracy).\n",
        "\n",
        "\n",
        "  # Regresión Logística - Logistic Regression-LR:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "  modelos.append(LogisticRegression(max_iter=1000, C=1.0, penalty='l1', solver='saga', random_state=42))\n",
        "  nombres.append('LR')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # k-Vecinos más Cercanos : k-Nearest-Neighbors-kNN:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
        "\n",
        "  modelos.append(KNeighborsClassifier(n_neighbors=3, weights='distance', algorithm='auto'))\n",
        "  nombres.append('kNN')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Árbol de decisiones-DecisionTree-DT:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "\n",
        "  modelos.append(DecisionTreeClassifier(\n",
        "      max_depth=20,\n",
        "      min_samples_split=2,\n",
        "      min_samples_leaf=1,\n",
        "      criterion='gini',\n",
        "      max_features=None,\n",
        "      random_state=42\n",
        "  ))\n",
        "  nombres.append('DTree')\n",
        "\n",
        "\n",
        "\n",
        "  # Bosque Aleatorio-RandomForest-RF:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "  modelos.append(RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=2, random_state=42))\n",
        "  nombres.append('RF')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # XGBoosting:\n",
        "  # https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier\n",
        "  # https://xgboost.readthedocs.io/en/stable/parameter.html\n",
        "\n",
        "  modelos.append(XGBClassifier(n_estimators=200, learning_rate=0.2, max_depth=10, random_state=42))\n",
        "  nombres.append('XGBoost')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Red neuronal de Perceptrón Multicapa-MLP:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
        "\n",
        "  modelos.append(MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, alpha=0.01, random_state=42))\n",
        "  nombres.append('MLP')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Máquina de Vectores de Soporte-SVM:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "\n",
        "  modelos.append(SVC(kernel='rbf', C=1.0, gamma=1, random_state=42))\n",
        "  nombres.append('SVM')\n",
        "\n",
        "  return modelos, nombres\n",
        "\n",
        "\n",
        "# Técnica de submuestreo (undersampling) y/o sobremuestreo (versampling) utilizada:\n",
        "mi_uoSampling = imbPipeline(steps=[\n",
        "    ('over', RandomOverSampler(random_state=42))\n",
        "])\n",
        "\n",
        "Xtv_uo, ytv_uo = mi_uoSampling.fit_resample(Xtraintest, ytraintest)\n",
        "\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *******************\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Entrenamos cada uno de los modelos y desplegamos la métricas de Train y Val.\n",
        "\n",
        "# NOTA: Observa que el método de Validación-Cruzada llama  a los resultados\n",
        "#       de \"validation\" como \"test\":\n",
        "\n",
        "modelos, nombres = mis_modelos()\n",
        "resultados = list()\n",
        "\n",
        "for i in range(len(modelos)):\n",
        "\n",
        "  # Definimos nuestro pipeline con las transformaciones y los modelos:\n",
        "  pipeline = Pipeline(steps=[('ct',columnasTransformer),('m',modelos[i])])\n",
        "\n",
        "  # Aplicaremos validación-cruzada:\n",
        "  micv = RepeatedStratifiedKFold(n_splits=5,\n",
        "                                 n_repeats=3,\n",
        "                                 random_state=5     # agreguemos una semilla para estabilizar resultados.\n",
        "                                 )\n",
        "\n",
        "\n",
        "  # Definimos las métricas que desamos recuperar:\n",
        "  mismetricas = {'miaccuracy':'accuracy','miprecision':'precision','mirecall':'recall',\n",
        "                 'mifi':'f1','miauc':'roc_auc','migmean':make_scorer(geometric_mean_score)}\n",
        "\n",
        "  # Llevamos a cabo el entrenamiento:\n",
        "  scores = cross_validate(pipeline,\n",
        "                          Xtv_uo,\n",
        "                          ytv_uo,\n",
        "                          scoring=mismetricas,\n",
        "                          cv=micv,\n",
        "                          return_train_score=True,\n",
        "                          )\n",
        "\n",
        "  # Guardemos el resultado de cada modelo para análisis posteriores.\n",
        "  resultados.append(scores)\n",
        "\n",
        "  # Desplegamos los valores de las métricas para verificar si no hay\n",
        "  # subentrenamiento o sobreentrenamiento:\n",
        "  print('>> %s' % nombres[i])\n",
        "  for j,k in enumerate(list(scores.keys())):\n",
        "    if j>1:\n",
        "      print('\\t %s %.3f (%.3f)' % (k, np.mean(scores[k]),np.std(scores[k])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYuOMBFjAI5h",
        "outputId": "935cf9bc-de8c-4953-ba50-9a3f387b6d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 15 folds for each of 12 candidates, totalling 180 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/opt/anaconda3/envs/master-ai-tec/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor modelo: 0.854633 usando {'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'max_iter': 1000}\n"
          ]
        }
      ],
      "source": [
        "# +++++++++ Inicia sección para incluir tu código ++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "modelo = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, alpha=0.01, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
        "    'alpha': [0.0001, 0.001],\n",
        "    'max_iter': [1000, 2000]\n",
        "}\n",
        "\n",
        "# param_grid = {\n",
        "#     'C': [0.1, 1, 10],\n",
        "#     'gamma': ['scale', 'auto', 0.1, 1],\n",
        "#     'kernel': ['linear', 'rbf', 'poly', 'sigmoid']\n",
        "# }\n",
        "\n",
        "# param_grid = {\n",
        "#     'n_estimators': [50, 100, 200],\n",
        "#     'learning_rate': [0.01, 0.1, 0.2],\n",
        "#     'max_depth': [3, 5, 10]\n",
        "# }\n",
        "\n",
        "# param_grid = {\n",
        "#     'n_estimators': [50, 100, 200],\n",
        "#     'max_depth': [3, 5, 10],\n",
        "#     'min_samples_split': [2, 5, 10]\n",
        "# }\n",
        "\n",
        "# param_grid = {\n",
        "#     'hidden_layer_sizes': [(50,), (100,), (100, 50)],  # Tamaño de las capas ocultas MLP\n",
        "#     # 'activation': ['tanh', 'relu'],                   # Función de activación\n",
        "#     # 'solver': ['adam', 'sgd'],                        # Algoritmo de optimización\n",
        "#     'alpha': [0.0001, 0.001],                         # Regularización L2\n",
        "#     'learning_rate': ['constant', 'adaptive']         # Tasa de aprendizaje\n",
        "# }\n",
        "\n",
        "# param_grid = {\n",
        "#     'C': [0.01, 0.1, 1, 10, 100],          # Inverso de la regularización\n",
        "#     'penalty': ['l1', 'l2'],               # Tipo de penalización\n",
        "#     'solver': ['liblinear', 'saga', 'lbfgs'],        # Algoritmos compatibles con L1 y L2\n",
        "# }\n",
        "\n",
        "# param_grid = {\n",
        "#     'n_neighbors': [3, 5, 7],\n",
        "#     'weights': ['uniform', 'distance', 'uniform'],\n",
        "#     'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "# }\n",
        "\n",
        "# param_grid = {\n",
        "#     'criterion': ['gini', 'entropy'],        # Función de medida de calidad\n",
        "#     'max_depth': [3, 5, 10, 20, 30],         # Profundidad máxima del árbol\n",
        "#     'min_samples_split': [2, 10, 20],        # Muestras mínimas para dividir un nodo\n",
        "#     'min_samples_leaf': [1, 5, 10],          # Muestras mínimas en una hoja\n",
        "#     'max_features': [None, 'sqrt', 'log2']\n",
        "# }\n",
        "\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=modelo,\n",
        "    param_grid=param_grid,\n",
        "    n_jobs=-1,\n",
        "    cv=micv,\n",
        "    scoring=mismetricas,\n",
        "    return_train_score=True,\n",
        "    refit='migmean',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "Xct = columnasTransformer.fit_transform(Xtv_uo)\n",
        "\n",
        "grid_result = grid.fit(Xct, np.ravel(ytv_uo))\n",
        "\n",
        "mejor_modelo = grid_result.best_estimator_\n",
        "\n",
        "# +++++++++ Termina sección para incluir tu código ++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "\n",
        "print(\"Mejor modelo: %f usando %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JkGo57zMXqn"
      },
      "source": [
        "## **Ejercicio 8**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n04HnK-ZX4vl"
      },
      "source": [
        "### **Escribe tus conclusiones finales de la actividad.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7s7iDgKYEn9"
      },
      "source": [
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "Para efectos de esta actividad, se compararon varios algoritmos de clasificación en el conjunto de datos: **SouthGermanCredit.asc**, mismo que comprende varios factores de clientes para la aporbación o rechazo de un crédito. Los modelos evaluados incluyen:\n",
        "\n",
        "- **Regresión Logística (LR)**\n",
        "- **k-Vecinos más Cercanos (kNN)**\n",
        "- **Árbol de Decisiones (DTree)**\n",
        "- **Bosque Aleatorio (RF)**\n",
        "- **XGBoost**\n",
        "- **Perceptrón Multicapa (MLP)**\n",
        "- **Máquina de Vectores de Soporte (SVM)**\n",
        "\n",
        "Los resultados mostraron que:\n",
        "\n",
        "- **SVM** logró el mejor rendimiento en términos de **accuracy** (0.909) y **precision** (0.990), aunque presentó un recall más bajo (0.826). Este equilibrio sugiere que el modelo tiene un buen desempeño en la identificación de clases positivas, pero podría mejorar en la captura de todos los casos positivos.\n",
        "\n",
        "- **XGBoost** también presentó un excelente rendimiento (accuracy de 0.878 y AUC de 0.954), lo que indica que es un modelo robusto para este tipo de tareas.\n",
        "\n",
        "- Por otro lado, **kNN** y **Árbol de Decisiones** mostraron un notable **overfitting**, con **accuracy** en el conjunto de entrenamiento igual a 1.000, mientras que en el conjunto de prueba fue significativamente menor. Esto resalta la necesidad de un manejo cuidadoso de hiperparámetros para evitar el sobreajuste.\n",
        "\n",
        "## Manejo de Clases Desbalanceadas\n",
        "\n",
        "El conjunto de datos original presentaba un desbalance en las clases, lo que podía llevar a que algunos modelos favorecieran la clase mayoritaria. Se utilizó **sobremuestreo** con el método `RandomOverSampler`, lo que permitió equilibrar las clases y mejorar el desempeño de los modelos en métricas como **recall** y **F1-score**.\n",
        "\n",
        "Este enfoque es crucial en problemas de clasificación donde el desbalance de clases puede distorsionar el rendimiento general de los modelos, haciéndolos menos efectivos en la detección de la clase minoritaria.\n",
        "\n",
        "## Optimización de Hiperparámetros\n",
        "\n",
        "Durante el ejercicio, se configuraron los hiperparámetros de cada modelo para promover la convergencia y evitar el sobreajuste:\n",
        "\n",
        "- Se utilizó un número máximo de iteraciones en la **Regresión Logística** y se ajustaron los parámetros como `max_depth` y `min_samples_split` en los modelos de árbol.\n",
        "- Para **XGBoost** y **MLP**, se seleccionaron cuidadosamente los parámetros de **learning_rate** y **hidden_layer_sizes** respectivamente.\n",
        "\n",
        "El ajuste de estos hiperparámetros es esencial para mejorar el rendimiento de los modelos, ya que permite encontrar un balance entre el ajuste del modelo a los datos de entrenamiento y su capacidad para generalizar a datos no vistos.\n",
        "\n",
        "## Recomendaciones para Mejoras Futuras\n",
        "\n",
        "- **Exploración de Más Estrategias de Muestreo**: Además de `RandomOverSampler`, sería beneficioso probar otros métodos como `SMOTE` o `ADASYN` para generar muestras sintéticas y mejorar aún más el rendimiento en clases desbalanceadas.\n",
        "\n",
        "- **Optimización de Hiperparámetros con Búsqueda en Rejilla**: Implementar `GridSearchCV` o `RandomizedSearchCV` para explorar un rango más amplio de hiperparámetros y así maximizar el rendimiento de cada modelo.\n",
        "\n",
        "- **Ensemble Learning**: Considerar el uso de técnicas de ensamblaje como **Voting Classifier** o **Stacking** para combinar modelos y mejorar la robustez general del sistema.\n",
        "\n",
        "## Reflexiones Finales\n",
        "\n",
        "Este ejercicio no solo permitió evaluar el desempeño de distintos algoritmos de clasificación, sino que también enfatizó la importancia de manejar adecuadamente las clases desbalanceadas y optimizar los hiperparámetros para obtener modelos efectivos y confiables. La experiencia adquirida en la selección y evaluación de modelos es invaluable para futuras tareas de modelado en problemas reales.\n",
        "\n",
        "\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto. +++++++++++\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-tW_CdUYMdl"
      },
      "source": [
        ">> ### **Fin de la Actividad de las Semanas 5 y 6.**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
